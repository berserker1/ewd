<html>
<head>
  <title>The Effective Arrangement of Logical Systems</title>
  <link href="https://fonts.googleapis.com/css?family=Lobster|Raleway" rel="stylesheet">
  <link href="assets/transcriptions.css" rel="stylesheet">
  <meta name="generator" content="convertArticle.pl">
</head>
<body>
<div class="metabar">
  <a href="index.html">HOME</a>
</div>
<h1>The Effective Arrangement of Logical Systems</h1>
<div class='body'>					
</p>
<p>
Edsger W.Dijkstra<br/>
Burroughs<br/>
Plataanstraat 5<br/>
NL-4565&nbsp;&nbsp;NUENEN<br/>
The Netherlands
<br/>
</p>
</div>
<div align="left">
<p>
We all know that when we have to design something &quot;large&quot; 
or &quot;difficult&quot;, we have to apply in one way or another the 
old adagium &quot;Divide and Rule&quot;. Our machines are made from 
components, our programs are made from modules and they should fit 
together via interfaces. That is fine, but it raises, of course, the 
questions how to chooose the modules and how to formulate the interfaces. 
This paper explores the main goals of modularization; being aware of 
them should assist us in evaluating the quality of proposed modularization.
</p>
<div align="center">
						<p class="noindent">
*&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*<br>
							
*</p>
					</div>
<div align="left">
<p>
An inspiring example of modularization outside of our own field is the way in 
which human knowledge is divided over the different scientific disicplines. 
Why do we teach different disciplines at our Universities? Why don't we teach 
all our students just &quot;knowledge&quot;? The answer is simple: our human 
skulls are too small and our days are too short. The amount of knowledge needed 
for each discipline must fit into a human head. Besides knowledge there are 
abilities, and human abilities have two characteristics: they take a lot of 
training before they are mastered, and thereafter the maintenance of their 
mastery requires that they are nearly daily exercised, for without such daily 
exercise they fade away. (This, by the way, is one of the explanations why 
the capable are always so busy.) In this sense, rather quantitative human 
characteristics impose a set of equally quantitative limitations on what we 
are willing to consider as a single scientific discipline.
</p>
<p>
But there are also internal, more structural constraints. I mean that just an 
arbitrary collection of scraps of knowledge of the right total amount does not 
constitute a scientific discipline! It must be sufficiently coherent and 
self-supporting: it must be possible to study the subject matter of a scientific 
discipline in isolation (or nearly so), largely independent of what is happening 
or known in other scientific fields. And the increased insight should enhance our 
abilities, our enhanced abilities should assist us in improving our insight.
</p>
<p>The above very rough sketch of how mankind as a whole has parcelled out its knowledge has been included because it also provides a model of how, on a microscopic scale, a single scientist works when he focusses his attention on an aspect of his problem. For every problem too large to be solved at a single stroke of the pen we try to apply a similar technique. We try to isolate various aspects of the problem and to deal with them in turn by &quot;concentrating our attention&quot; on them. (The latter does not mean that we study them in complete isolation: through the corners of our eyes we usually still look at all we are temporarily ignoring!)</p>
<p>The usual catchphrase for this technique is &quot;separation of concerns&quot;. Although very adequate from a descriptive point of view, it raises of course the same sort of questions as we raised initially about modules and interfaces, such as &quot;Which concerns should be separated?&quot; and perhaps &quot;After separation, how do they combine again?&quot;. This similarity is a rather clear hint that the successful &quot;modularization&quot; of a large information processing system is <em>not</em> a trivial matter.</p>
<div align="center">
							<p class="noindent">
*&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*<br>
								
*</p>
						</div>
<div align="left">
<p>
The discovery that from a &quot;larger&quot; concern, a few &quot;smaller&quot; 
concerns can be successfully extracted usually ranks as a scientific discovery. 
Let me mention a few of them from our own field, so that we know, what we are talking 
about.
</p>
<p class="noindent">a) The isolation of the definition of the syntax in the task of defining programming languages. (John Backus, 1959; as BNF immediately used in the definition of ALGOL 60.)</p>
<p class="noindent">b) The isolation of logical aspects of operating systems via the model of cooperating sequential processes. (Edsger W.Dijkstra, 1961; quickly thereafter used in the design of the THE Multiprogramming System.)</p>
<p class="noindent">
c) The isolation of programming language semantics computational histories. (C.A.R.Hoare, 
1968; immediately used in the axiomatic definition of semantics.)
</p>
<p>
I think that the above three examples are fairly typical: all three 
&quot;separations&quot; (or &quot;isolations&quot; or &quot;extractions&quot;) 
have been hightly rewarding. Firstly it was quite clear that the people responsible 
were not just playing a game, they extracted what seemed a very relevant and possibly 
manageable aspect from a large and burning problem. Secondly they created a realm of 
thought rich enough to have many thoughts in!
</p>
<p>Example (a) opened the way for parsing theory, example (b) for the theory of synchronization, deadlock prevention etc., and example (c) has opened the way for practicable techniques for proving the correctness of programs. In all three cases the problems addressed can now be dealt with quite professionally. All three are easily &quot;rich&quot; enough to be the subject of a one-semester course in a University curriculum, and all three are so well separated from other concerns that such a one-semester course could be fairly self-contained.</p>
<p>Yet another observation should be made. By ignoring, abstracting, generalizing (or whatever verb you wish to use to indicate the not taking into account of some facts) a dual goal has been achieved: thanks to it the theories are of a wide applicability and at the same time of an internal simplicity. (Think of the tremendous simplification of the theory of cooperating sequential processes that was made possible by <em>not</em> dragging speed ratios into the picture! If knowledge about speed ratios had been essential, the correctness arguments would have been an awful mixture of discrete and continuous arguments, and it would all have become very complicated.) It has been said that &quot;everything can be regarded as a special instance of something more general&quot;, but I would like to add that there is only a point in doing so, provided that the general view <em>simplifies</em> our arguments. This condition is certainly not met when the more general something can only be understood via a case analysis ranging over the different special instances.</p>
<div align="center">
								<p class="noindent">
*&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*<br>
									
*</p>
							</div>
<div align="left">
<p>
Another inspiring example is provided by the arrangement of mathematical arguments.
</p>
<p>
Of our various thinking activities I shall reserve the term &quot;reasoning&quot; for 
all manipulations that are formalized &#x2014;or could readily be so&#x2014; by 
techniques such as arithmetic, formula manipulation or symbolic logic. These techniques 
have a few common characteristics.
</p>
<p>First of all, their application is straightforward in the sense that as soon as it has been decided in sufficient detail, <em>what</em> has to be achieved by them, there is no question anymore <em>how</em> to achieve it. And whenever such a technique has been applied, the question whether this has been done correctly is undebatable.</p>
<p>
Secondly &#x2014;and this is not independent of the first characteristic&#x2014; we 
know how to teach these techniques: arithmetic is taught at the primary school, formula 
manipulation at the secondary school, and symbolic logic at the university.
</p>
<p>
Thirdly, we are very good at doing modest amounts of reasoning. When large amounts of it 
are needed, however, we are powerless without mechanical aids. To multiply two two-digit 
numbers is something we can all do; for the multiplication of two five-digit numbers, 
most of us would prefer the assistance of pencil and paper; the multiplication of two 
hundred-digit numbers is a task that, even with the aid of pencil and paper, most of us 
would not care to undertake.
</p>
<p>In order to reach a conclusion the amount of reasoning needed is often the stumbling block, and I have yielded to the temptation to relate the effectiveness with which we have arranged our thoughts to the degree in which we have reduced the amount of reasoning needed. A recent experience has confirmed that this seems sensible. I was compiling a collection of what I thought to be impressively elegant solutions. The first thing that struck me was the surprising degree of consensus among my mathematical colleagues: when I asked them for suggestions they often came with the same examples. The second thing that struck me was that, when I showed any of them a solution from the collection that happened to be new for him, I evoked uniformly the same reaction: laughter! The third thing that struck me, however, is in this context the most important one: all the impressively elegant solutions were very short. I therefore ask you to subscribe &#x2014;at least until the 
discussion after this talk&#x2014; my thesis that the effectiveness with which we think is 
closely related to the reduction of the amount of reasoning needed, because, as soon as you 
have subscribed that thesis, you will agree with me that it is a good thing to know by what 
methods we can reduce that amount and by what methods we can increase it: those of the 
former category are the ones to be applied, those of the latter category are the ones to be 
avoided.
</p>
<div align="center">
									<p class="noindent">
*&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*<br>
										
*</p>
								</div>
<div align="left">
<p>An obvious method is avoiding repetition. When multiplying two ten-digit numbers with pencil and paper we constantly appeal to the 10 by 10 multiplication table of the products of one-digit factors. Whether or not we know the multiplication table by heart or have it written out in front of us for quick reference is unimportant for the purpose of this discussion. What is important is that while multiplying those two ten-digit numbers, we have 100 <em>theorems</em> at our disposal, of which <code>7 * 8 = 56</code> is an instance. If we <em>know</em> how to count, or <em>know</em> how to add, we can <em>prove</em> that the product <code>7 * 8</code> equals <code>56</code>, but that proof requires a certain amount 
of reasoning, so much as a matter of fact that we would not like to do it over and over 
again, every time we need the product <code>7&nbsp;*&nbsp;8&nbsp;</code>. Hence the knowledge that that 
product equals <code>56</code> is cast into a theorem; together with the other <code>99
</code> theorems it forms what is known as the multiplication table.
</p>
<p>
Another remark of a directly quantitative nature is that we would not expect much use for 
a theorem whose statement is longer than its proof: instead of appealing to the theorem it 
would be simpler &#x2014;at least &quot;shorter&quot;&#x2014; to mention directly its proof.
</p>
<p>The quantitative remarks in the two previous paragraphs, although of some relevance, do, however, not tell the complete story: if they did, there would be no point in stating and proving a lemma that is used only once, and there <em>is</em> a point in doing so.</p>
<p>
Suppose that the total proof of a Theorem consists of two parts:
</p>
<p class="noindent">
A: a proof of the Theorem based on the validity of a Lemma, and
</p>
<p class="noindent">
B: a proof of aforementioned Lemma.
</p>
<p class="noindent">
If both proofs are correct, the Theorem has been established, but suppose that part <code>B 
</code> is shown to contain a flaw.  If we cannot correct the flaw, or perhaps even discover 
that the Lemma does not hold, we are in bad shape.  If, however, we can correct the flaw in 
part <code> B </code>, its correction is the only thing that needs to be done: part <code>A 
</code>survives unchanged and unattended. Thinking about the last scenario I have come to the conclusion that its likelihood is, all by itself, a sufficient justification for splitting up the total proof &#x2014;straight from the axioms, so to speak&#x2014; in part 
<code>A </code> relying on a lemma and a part <code>B </code> establishing that Lemma, even 
if part <code>A </code> refers only once to it.  The conclusion seems to be that we not only 
seek to reduce the amount of reasoning eventually needed when all would have gone well, but 
also the amount of reasoning to be expected in view of our fallibility.
</p>
<p>
But, again, there is more to it.  Splitting the total proof into parts <code>A </code> and 
<code>B </code>, connected by a Lemma used in <code>A </code> and proved in <code>B </code> 
means
</p>
<p class="noindent">
1)  that we can study <code>B </code> ignoring <code>A</code>, i.e. ignoring the way in 
which the Lemma is used: we only need to consider what the Lemma asserts
</p>
<p class="noindent">
2)  that we can study <code>A </code> ignoring <code>B </code>, i.e. ignoring the way in 
which the Lemma is proved: again we only need to consider what the Lemma asserts.  Because 
the statement of the Lemma can be expected &#x2014;see above&#x2014; to be shorter than its 
proof, also here we have to take less into account, and that is nice in view of another 
human limitation, i.e. the limited span of our attention.
</p>
<p>
Such a separation of concerns is, however, not only nice in view of our limited span of 
attention, it has a much profounder consequence.  It gives us the freedom of replacing part 
<code>B </code>by a shorter or nicer proof of the Lemma as soon as we find one, it gives us the freedom of replacing part <code>A </code> by a nicer or shorter proof of the Theorem 
as soon as we find one.  As long as the Lemma remains the same, changing one part does not 
invalidate the other.  This observation makes it abundantly clear &#x2014;at least in my 
mind&#x2014; that we should not regard the appeal to the Lemma as it occurs in part <code>A 
</code> as an abbreviation of its proof as described in part <code>B </code>. The appeal to a lemma is to what the lemma states, and <em>not</em> to its proof: the main purpose of the introduction of the explicitly stated Lemma was precisely to make part <code>A </code>a <em>consistent</em> whole that is <em>independent</em> of the particular shape of <code>B 
</code>.
</p>
<div align="center">
										<p class="noindent">
*&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*<br>
											
*</p>
									</div>
<div align="left">
<p>
The above must sound very familiar to every mathematician that has been trained always to 
try consciously to present his proofs both as concise and as clear as possible.  (That not 
all mathematicians have been trained that way, is another matter that need not concern us 
now.)  Computing scientists &#x2014;the other designers of what I called in my title: 
&quot;logical systems&quot;&#x2014; seem, amazingly enough, to be in general less aware of it. They are in general aware of the circumstance that what on one level of detail can be regarded as an unanalysed whole, can be regarded at a next level of greater detail as a composite object, they are often not fully aware of its implications. The analogy with mathematical proofs tells us that whenever we regard a whole as composed of parts, the way of composition must define how the relevant properties of the whole depend functionally on the <em>properties</em> of the parts, without the need of taking their internal structure into account.</p>
										<p>
Let me give you one of my cherished examples.  We consider a program part <code>S </code> for 
the computation of the remainder, more precisely, a program part <code>S </code> satisfying 
for constant <code>c </code> and <code>d </code>:
</p>
										<blockquote>
											<table width="100%" border="0" cellspacing="2" cellpadding="0">
												<tr>
													<td><code>(c &ge; 0 <u>and</u> d &gt; 0) &#x21D2; wp(S, r = c <u>mod</u> d)</code></td>
													<td>
														<div align="right">
															
(1)
</div>
													</td>
												</tr>
											</table>
										</blockquote>
										<div align="left">
											<p class="noindent">
(in words:  <code>c &ge; 0 <u>and</u> d &gt; 0 </code> implies the weakest pre-condition for 
the initial state such that activation of <code>S </code> is certain to establish a final 
state satisfying the post-condition <code>r = c <u>mod</u> d</code>).  Consider for <code>S 
</code> the following program part:
</p>
											<blockquote>
												<table width="100%" border="0" cellspacing="2" cellpadding="0">
													<tr>
														<td width="30%"><code>{c &ge; <u>and</u> d &gt; 0} </code></td>
														<td width="60%">
															<div align="left">
																<code>r, dd := c, d;</code></div>
														</td>
														<td>
															<div align="right">
																
																(2)</div>
														</td>
													</tr>
													<tr>
														<div align="left">
															<td style="text-indent: 4.0em" width="30%"></td>
															<td width="60%"><code><u>do</u> r &gt; dd &rarr; dd:= 2 * dd <u>od</u>;</code></td>
															<td></td>
														</div>
													</tr>
													<tr>
														<td style="text-indent: 4.0em" width="30%"></td>
														<td width="60%"><code><u>do</u> dd &ne; d &rarr; dd:= dd / 2;</code></td>
														<td></td>
													</tr>
													<tr>
														<td style="text-indent: 6.0em" width="30%"><code></code></td>
														<td width="60%"><code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<u>if</u> r &ge; dd &rarr; r:= r - dd</code></td>
														<td></td>
													</tr>
													<tr>
														<td style="text-indent: 6.0em" width="30%"></td>
														<td width="60%"><code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><font face="Courier New,Courier,Monaco"><b>&#x25AF;</b></font><code> r &lt; dd &rarr; skip</code></td>
														<td></td>
													</tr>
													<tr>
														<td style="text-indent: 6.0em" width="30%"></td>
														<td width="60%"><code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<u>fi</u></code></td>
														<td></td>
													</tr>
													<tr>
														<td style="text-indent: 4.0em" width="30%"></td>
														<td width="60%"><code><u>od</u> {r = c <u>mod</u> d}</code></td>
														<td></td>
													</tr>
												</table>
											</blockquote>
											<p>Many programmers, I have discovered, don't hesitate to consider this program part <code>S </code>as composed (primarily) of three parts, viz. of the form</p>
											<p style="text-indent: 4.0em"><code>&quot;S&quot; = &quot;S0; S1; S2&quot;</code></p>
											<p class="noindent">i.e. the outermost syntactical decomposition. The point, however, is that nowhere the properties of these parts <code>S0, S1</code>, and <code>S2 </code>have been stated, on account of which we can conclude that <code>S </code>satisfies (1). This point becomes a problem as soon as it is discovered that program (2) is wrong. It contains a well-engineered bug: in those cases where <code>c </code>divided by <code>d </code>leaves a remainder = 0 and, in addition, the quotient is a power of 2 , the final state satisfies <code>r = d </code>instead of <code>r = 0 </code>. As it stands we can only conclude that program (2) <em>as a whole</em> is wrong; we <em>cannot</em> &#x2014;although regarding it as a concatenation of three statements&#x2014; decide which of these statements is in error. That question is void.</p>
											<p>And, as a matter of fact, we can repair it in different ways. Either we replace <code>S1 </code>by</p>
											<p style="text-indent: 4.0em"><code>&quot;<u>do</u> r &ge; dd &rarr; dd:= 2 * dd <u>od</u>&quot;</code></p>
											<p class="noindent">or replace <code>S2 </code>by</p>
											<p style="text-indent: 4.0em"><code>&quot;<u>do</u> r &ge; d &rarr; dd:= dd / 2</code></p>
											<p style="text-indent: 6.0em"><code><u>do</u> r &ge; dd &rarr; r:= r - dd <u>od</u></code></p>
											<p style="text-indent: 4.0em"><code><u>od</u>&quot;</code></p>
											<p>If we had <em>chosen</em> the properties</p>
											<blockquote>
												<table width="100%" border="0" cellspacing="2" cellpadding="0">
													<tr>
														<td><code>P0 </code>&#x21D2;<code> wp(S0, P1), P1 </code>&#x21D2;<code> wp(S1, P2), and P2 </code>&#x21D2;<code> wp(S2, P3)</code></td>
														<td>
															<div align="right">
																
															(3)</div>
														</td>
													</tr>
												</table>
											</blockquote>
											<div align="left">
												<table width="100%" border="0" cellspacing="2" cellpadding="0">
													<tr height="25%">
														<td width="7%" height="25%">with</td>
														<td height="25%"><code>P0: c &ge; 0 <u>and</u> d &gt; 0<sup>&nbsp;</sup></code></td>
													</tr>
													<tr height="25%">
														<td width="7%" height="25%"></td>
														<td height="25%"><code>P1: r <u>mod</u> d = c <u>mod</u> d <u>and</u> (<u>E</u> i: i &ge; 0: dd = d * 2<sup>i</sup>) <u>and</u> 0 &le; r</code></td>
													</tr>
													<tr height="25%">
														<td width="7%" height="25%"></td>
														<td height="25%"><code>P2: P1 <u>and</u> r &lt; dd<sup>&nbsp;</sup></code></td>
													</tr>
													<tr height="25%">
														<td width="7%" height="25%"></td>
														<td height="25%"><code>P3: r = c <u>mod</u> d<sup>&nbsp;</sup></code></td>
													</tr>
												</table>
												<p class="noindent">then the bug would have been localized in <code>S1 </code>as it may fail to establish <code>P2 </code>.</p>
												<p class="noindent"><u>Note</u>. On account of the semantic definition of the semicolon</p>
												<p style="text-indent: 4.0em"><code>wp(&quot;S1; S2&quot;, R) = wp(S1, wp(S2, R))</code></p>
												<p class="noindent">we derive</p>
												<p style="text-indent: 4.0em"><code>wp(&quot;S0; S1; S2&quot;, R) = wp(S0, wp(S1, wp(S2, R)))</code></p>
												<p class="noindent">and conclude that (3) indeed allows us to derive</p>
											</div>
											<blockquote>
												<table width="100%" border="0" cellspacing="2" cellpadding="0">
													<tr>
														<td><code>P0 </code>&#x21D2;<code> wp(&quot;S0; S1; S2&quot;, P3)</code></td>
														<td>
															<div align="right">
																
															(End of Note.)</div>
														</td>
													</tr>
												</table>
											</blockquote>
											<div align="left">
												<p>The moral of the story is that we can only claim that a whole has been properly composed of parts provided the necessary properties of the parts have been decided. Without that specification it is, as if we are trying to build up a mathematical theory while giving only the proofs of our theorems and lemmata, but not the theorems and lemmata themselves! I have, therefore, decided for myself that such specification of the parts is an absolutely essential constituent of the whole design. After all I have said, this decision may strike you as obvious, as nearly trivial. I am unhappy to report that it is not generally accepted. Quite regularly I see texts arguing that &quot;we cannot impose upon the poor programmer the additional burden of also supplying the assertions that correctness proofs (still) need&quot;. Depending on the attitude of the writer, either today's proving techniques are blamed for &quot;still&quot; needing such assertions &#x2014;in that case the author usually does not mention what alternative proving techniques he has in mind&#x2014; or the author now proposes to apply Artificial Intelligence techniques for deriving such assertions mechanically. I hope to have made clear why I regard the latter as a somewhat nonsensical activity; the assertions reflect an explicit choice of the designer, a responsibility that certainly cannot be delegated to a guessing AI-system. (For instance: in the above example we could have replaced in <code>P1 </code>and in <code>P2 </code>, or in <code>P1 </code>only, the term <code>r <u>mod</u> d = c <u>mod</u> d </code>by the more stringent <code>r = c </code>.) An &quot;automatic specification guesser&quot; that is only fed with a single instance of each part is almost certainly bound to be overspecific, and the whole activity strikes me as putting the cart before the horse.</p>
												<p class="noindent"><u>Example</u>. Given the following proof:</p>
												<p class="noindent">&quot;The theorem is obvious, because</p>
												<p><code>(x1</code> <code>-</code> <code>x0)(x2</code> <code>-</code> <code>x3) + (x2</code> <code>-</code> <code>x0)(x3</code> <code>-</code> <code>x1) + (x3</code> <code>-</code> <code>x0)(x1</code> <code>-</code> <code>x2)</code> <code>=</code> <code>0</code> &quot; ,</p>
												<p class="noindent">can you guess the theorem? It is &#x2014;this is a hint&#x2014; a very well known theorem that is usually proved in a rather indirect way. (End of example.)</p>
												<div align="center">
													<p class="noindent">
													*&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*<br>
														
													*</p>
												</div>
												<div align="left">
													<p>I have shown you a small example, specifically manufactured to illustrate the nature of the dilemma. Let me now turn to a more grandiose example that has been provided by &quot;the real world&quot;. The original design of the IBM650 had the very special feature that the attempted execution of a special little program loop blew one of the fuses of the machine. Needless to say, this very special feature was not mentioned in the manual, but, programmers being as they are, they not only discovered it, they also used it in at least one organization, where reservations of machine time were extended with the down-time, when the machine broke down during your period of reservation. Programmers who had a one-hour reservation for a debugging session used the little loop when, after ten minutes of testing, they discovered a bug whose patching required some peaceful thinking!</p>
													<p>The decomposition into the two parts &quot;hardware&quot; and &quot;software&quot; is certainly a time-honoured one, but in this case it was defective. As soon as the aggregate whole was required not to blow fuses while yet it did, <em>none</em> of the two parts could be proved to be wrong or to be correct. The maintenance engineer could argue that all programmers knew that the machine was such that that little loop would blow a fuse and that, therefore, they should not include it in their programs. The programmers, from their side, could argue that the manual nowhere stated that upon the attempted execution of that little loop the machine had to blow one of its fuses! The could throw the blame on the other party indefinitely, and the only way to end this ping-pong game is by <em>choosing</em> a well-defined interface. Either it is decided that the fuse should not be blown &#x2014;which means a change in the hardware design&#x2014; , or it is decided that the fuse should be blown, and then all programmers have the obligation to program around it.</p>
													<p>I definitely prefer the first alternative, not so much because I am more of a programmer than of a circuit designer, but because in the interplay between hardware and software we have the greatest variability at the software side. It is therefore simpler to propagate the obligation of fixing the bug through the limited number of machines than through all the programs that are or will be made for that type of machine. I have the sad impression that in user communities, management often takes the undesirable decision and obliges its programmers to program around such deficiencies.</p>
													<p>The story about the fuse is old and nearly forgotten. We should, however, remember it as a paradigm for the sad situation in which the majority of today's programmers are supposed to do their work. I know of a respectable colleague who, in the year of the Lord 1976 is developing the basic software for a machine of a less respectable design: its hardware specifications are so obscure that quite regularly he has to get access to the prototype in order to discover experimentally what some commands are supposed to achieve! He has to do so under the assumption that the prototype is in perfect working condition, the trouble, of course, being that, logically speaking, that &quot;perfect working condition&quot; is, as yet, undefined. Together with the hardware designers he has to decide &quot;after the fact&quot;, which machine they should have had in mind to build. I like to believe that this is an extreme case, but have no grounds for doing so.....</p>
													<p>The complete functional specification of a machine must be given without any reference to its internal structure if, in the whole system, the machine is to be recognized as a part of a composite whole. This, however, does not only apply to hardware &#x2014;&quot;concrete machines&quot;, if you like&#x2014; , it is equally applicable to the abstract machines known as higher-level programming languages. Only when their semantics are fully defined <em>without any reference to implementation details</em> such as compilers, binders, interrupts and what have you, only then has the separation of concerns been effectuated that makes any progress possible. It is in this respect disheartening to observe that many a modern high-level language user is much worse off than the average programmer a quarter of a century ago. In the old days programmers used to have a complete functional description of their machine at their disposal and, as a result, they could know exactly what they were doing. This in sharp contrast to the majority of the so-called high-level programming languages, the semantics of which are only so loosely indicated that most young programmers have lost the sense of complete control that we used to have. They live in a woolly environment in which the notion that a program is either correct or not is, by definition, not applicable.</p>
													<p>A politically complicating factor is that the world's largest computer manufacturer has probably not the slightest incentive to change this state of woollyness of the programming languages it supports, because this woollyness only acts as its advantage as long as its products are accepted as what are euphemistically called &quot;de facto standards&quot;. In the case of a well-defined programming language, it would have the obligation to implement that correctly and would run the risk of a competitor providing a better implementation; as things are its implementations are taken as &quot;the definition&quot;. Such political considerations make its unwillingness to support such well-defined languages as, say, ALGOL 60 only too understandable.</p>
													<p>So much for the ill effects of lacking specifications.</p>
													<div align="center">
														<p class="noindent">
														*&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*<br>
															
														*</p>
													</div>
													<div align="left">
														<p>I hope that in the above I have convinced you that, in the invention of the complex composite systems we are considering, a rigorous definition of the essential <em>properties</em> of the parts is not a luxury but a necessity. In the final part of my talk I would like to tackle the more elusive question &quot;By virtue of what type of properties can parts be nice or ugly?&quot; It is the question what interfaces to invent. I called this question &quot;elusive&quot; because it is as impossible to give a final answer to it is impossible to teach young mathematicians how to discover beautiful theorems. What we can do &#x2014;and, in fact, do while teaching mathematics&#x2014; is explaining why we think that some theorems are beautiful. In a similar vein we should be able to explain to young computer scientists what virtues to look for when they are evaluating or considering a proposed set of interfaces. It is in this connection a good thing to remember that one of the main roles of the decomposition of a whole into parts was the localization of the bug when something went wrong.</p>
														<p>Again, let me start with a very simple example. Suppose that we have to control a printing device that accepts 27 different commands &#x2014say the printing of the 26 letters of the alphabet and the blank&#x2014 . If we control this device with a ternary machine, each command could be specified with three ternary digits because 3<sup>3</sup>=27. But suppose now that we are to control such a device with a binary machine. We would then need five bits for a command. Immediately the question arises what to do with the nonsensical remaining <code>32 - 27 = 5 </code>possible &quot;commands&quot;. One answer would be that it does not matter because no correct program would ever send any of these five nonsensical commands to the device. But this would be a very silly choice, for it would give the designer of the device the licence to make it in such a way that a nonsensical command could cause a jam in the printing mechanism, and as soon as he has done that it is possible to write erroneous programs that, besides not producing the right results, may wreck the installation. Such a silly interface would cause the ill effects of an erroneous program to spread. Another possibility would be to postulate that such nonsensical commands are ignored by the device. That is safe as far as the working condition of the device is concerned but it is still silly: presumably it was not the programmer's intention to send such silly skip commands to the printing device and, if such a command is sent to the device, we may assume that something in the execution of his program has gone wrong. The sensible reaction is, on the one hand to protect the device from being wrecked and on the other hand to signal an error, thus giving the programmer another way of protecting himself. An alternative way of doing away with the problem would be to extend the character set of the printing device with another five characters.</p>
														<p>This, again, was a simple example, specially manufactured to illustrate the problem; but if we look for it, we can find the silly choice made many times, and on a much larger scale. A famous example is the coupling to a general purpose computer of peripherals that may signal to the central processor that they require a certain service from it within a given number of milliseconds; in the worst situation the irrecoverable malfunctioning that results when the central processor fails to meet its real-time obligation is not even signalled! In any case the real-time obligation of the central processor with respect to such a peripheral places a heavy and ugly burden upon the system designer who, for instance, must guarantee that the interrupt is never disabled for too long a period of time.</p>
														<p>We find the same flaw when compilers accept syntactically incorrect programs without warning or when system integrity relies on the correctness of the compilers used.</p>
														<p>The quoted examples are instances of a general case. We are dealing with classes of strings: strings of characters representing a source program, strings of words representing object programs, strings of commands controlling a device, etc. Either such a class of strings contains all the strings that are physically possible, as in the case of coding the 27 commands to the printer with three ternary digits. In this case there is no redundancy, and we note in passing that under many circumstances such an absence of redunancy is undesirable. Or &#x2014;and this seems to be the much more common case&#x2014 the class of intended strings does not contain all the ones that are physically possible, i.e. our intended strings are represented by the physically ones with a certain redundancy. Using the terms &quot;legal&quot; and &quot;illegal&quot; for strings within and beyond the intended class respectively, we can formulate the following conclusions.</p>
														<p class="noindent">1) The class of legal strings must be defined precisely. If this already presents serious problems, this is a warning not to be ignored.</p>
														<p class="noindent">2) Any part processing such a string should establish whether the string is legal or not. If this presents serious problems, this is a warning not to be ignored.</p>
														<p class="noindent">3) Any part processing such a string should not react upon an illegal string as if it were a legal one.</p>
														<p class="noindent">4) Processing an illegal string may not wreck the part: none of the relations which are carefully kept invariant during the processing of legal strings may be destroyed by the processing of an illegal string.</p>
														<p class="noindent"><b>Note</b>. If program component <code>B </code>processes a string produced by program component <code>A </code>without satisfying the above conditions 2 through 4 &#x2014;for instance because it is felt to be too expensive to make component <code>B </code>that way&#x2014; , we should regard components <code>A </code>and <code>B </code>as belonging to the same part. (End of Note.)</p>
														<div align="center">
															<p class="noindent">
															*&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*<br>
																
															*</p>
														</div>
														<div align="left">
															<p>To wind up I would like to make two suggestions: I would like to suggest to programmers that they have a closer look at mathematics, and to mathematicians that they have a closer look at programming. By virtue of their tradition mathematicians have a more explicit appreciation for what it means to be rigorous, as a result of the power of currently available machines programmers are more aware of the problems created by sheer size.</p>
															<p>I do not suggest that programmers should stuff their heads with mathematical results, but I would like them to get a better appreciation for how and how effectively mathematics are organized. If they do so I expect them to discover that many current topics in computing science are in a sense null-problems as they address problems that should never have been there to start with. I expect them to discover that if they are problems now, we are suffering from the pains of a hell into which our own sins have sent us. I also expect them to discover that these problems are only soluble by starting over again, and that the perpetuation of some old mistakes is the worst mistake we can make now. As very likely candidates for null-problems I mention those associated with compatability, portability and protection.</p>
															<p>I also feel that many a mathematician could profit from the exposure to programming. I have that feeling because, while studying mathematical texts, I now very often observe as my reaction towards the author &quot;He must be a very poor programmer!&quot; We, as programmers, have, for instance, been so trained to avoid case-analysis like the plague that it is not unusual at all to encounter a mathematical argument, the length of which can be halved, perhaps even be halved a number of times.</p>
															<p>While preparing this invited speech I had to guess at what type of audience I would eventually address. The title of the Symposium's subject &quot;Mathematical Foundations of Computing Science&quot; was my only indication. If I have the privilege of addressing a primarily mathematically interested audience, it is clear how my ending note should sound, for in that case I can only urge you, Mathematicians, <em>not</em> to confine with respect to Computing Science your interest to its foundations! The praxis of computer programming needs you as much as you need its challenge, if Mathematics is to remain the Queen of Sciences.</p>
														</div>
													</div>
													<br>
													<table width=100% border=0 cellspacing=0 cellpadding=0>
														<tr valign=top>
															<td width="70%" valign=top nowrap>May 1976<br>
																NUENEN, The Netherlands</td>
															<td width="30%" valign=top nowrap>prof.dr.Edsger W.Dijkstra<br>
																Burroughs Research Fellow</td>
														</tr>
													</table>
													<hr />
													<div id="footer">
														<font size="-1">transcribed by Karl Cooper<br />revised <csobj format="MedDate" h="16" region="15" t="DateTime" w="94">Fri, 1 Oct 2010</csobj></font></div>
												</div>
											</div>
										
									
										
										
										
										
										
										
										
										
										
										
										
										
										
										
										
									
										
									
										
											
										
	</body>
</html>



</div>
</body>
</html>
