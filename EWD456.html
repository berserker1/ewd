<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"><html><head><link href="assets/transcriptions.css" rel="stylesheet" media="screen"><link href="https://fonts.googleapis.com/css?family=Lobster|Raleway" rel="stylesheet"><meta http-equiv="content-type" content="text/html;charset=ISO-8859-1"><title>E.W.Dijkstra Archive: Determinism and recursion versus non-determinism and the transitive closure (EWD 456)</title><STYLE TYPE="text/css">	<!--	P {text-indent: 30pt;}	-->	</STYLE></head><body><div id="title"><h1>Determinism and recursion versus non-determinism and the transitive closure</h1></div>		<div align="right">			<p><a href="https://www.cs.utexas.edu/~EWD/ewd04xx/EWD456.PDF">EWD456</a></p>		</div>		<u>Determinism and recursion versus non-determinism and the transitive closure</u>.<p>Two years ago I pondered about the design of an intellectually well-manageableprogramming language, the implementation of which would allow apotentially very high degree of concurrency without imposing it (nor, ofcourse, requiring the amount of temporary storage that would be needed tosimulate the concurrency.) One can try to reach such a goal by the introductionof multi-component datatypes like in APL, but then the price to bepaid seems to be a very elaborate repertoire of operations, and, havingseen where that leads to, I obviously did not want to go down &quot;that slipperyroad of reasoning&quot;.</p><p>I found myself considering the massaging &#x2014;under control of a verylimited repertoire&#x2014; a set of <var>n</var>-tuples, the possibility of concurrence being modelled by the simultaneous creation of a whole lot of such <var>n</var>-tuples. Wanting to be kind to my hardware friends, I focussed my attention at a very early stage to the question whether I could fix <var>n</var>. Extremely far-fetched analogies suggested that if <var>n</var> could be fixed, it should be fixed at 4, and as a result the <var>n</var>-tuples became 4-tuples and were tentatively called &quot;quadrons&quot;. In a next stage my (originally hardware) friend C. S. Scholten came with an argument that, whatever could be done using <var>n</var>-tuples could be done &#x2014;after a fashion equally well&#x2014; with <var>k</var>-tuples, with <var>k</var> = entier((<var>n</var>+1)/2)+2. After this encouraging confirmation of my hunches, we got stuck completely and the exercise was dropped for at least one-and-a-half year.</p>		<p>A number of months ago, the exercise was picked up again by W.H.J.Feijen and M.Rem (with some stress on the latter) and occasionally me. Analyzing the previous failure we came to the conclusion that the fixation <var>n</var> = 4 had been premature, so we dropped it and from then onwards called our <var>n</var>-tuples &quot;associons&quot;. We tried again &#x2014;and some of our efforts that need not concernus here, have in the mean time again been unmasked as dead alleys&#x2014;, andone thing seems to have emerged more or less solidly: about our most centralprimitive operation can be viewed as forming the transitive closure, i.e.given a set of nodes of a finite, directed graph as &quot;starting set&quot;, determinethe set of all nodes reachable via a directed path from at least one of thenodes of the starting set.</p>		<div align="center">			*&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*<br>			*</div>		<p>The incentive to start the experiment two years ago was only partlya desire to explore the programming of potentially high concurrency, it wasalso the result of my difficulties in writing a &#x2014; &quot;sequential&quot;, i.e. ALGOL-like&#x2014; program that should determine the convex hull of a (large) set ofgiven points in three dimensions. For the convex hull in two dimensions Iknew a host of algorithms; I tackled the three-dimensional version of thatproblem in the expectation that from that exercise I should be able to learnsomething about programming methodology. The first thing I learned was thatI could not solve the problem nicely: what I tried became so messy &#x2014;at leastto my standards&#x2014; that I aborted each effort long before I had reached aworking solution. So I dropped that problem for the time being &#x2014;apparentlynot ripe for it yet&#x2014;and started to write a book instead.</p>		<p>The problem of the convex hull in three dimensions presents somedifficulties which are absent in the two-dimensional version: it is notpatently obvious how the result &#x2014;and, therefore, intermediate states&#x2014; shouldbe represented in an (essentially) &quot;linear&quot; store, nor is it patently clear,how the two-dimensional surface should be processed by a &quot;sequential&quot; machine.Wanting to include in my book a true and non-embellished design history,&#x2014;including the risk of failure&#x2014;, I needed a non-trivial problem I had never successfully solved before. I chose the problem of the convex hull in three dimensions, and, after having reported what I had learned from my non-successful attempts, I started to try to solve the problem in earnest. I succeeded &#x2014;as a matter of fact: I arrived at a solution which filled me with some pride&#x2014;and my solution had two characteristics which seem worth mentioning. Theone observation is that the need to introduce more-dimensional arrays emergednowhere; the second observation is the central role played &#x2014;at two/threeplaces, in different disguises&#x2014; by the task to determine a transitive closure.More precisely:</p><p>Given a finite set <var>S</var> and a subset <var>B</var>; for each element <var>x</var> of <var>S</var>, zero or more other elements of <var>S</var> are by definition &quot;the consequences of <var>x</var>&quot;. Determine the set <var>V</var>, defined by<br>			1)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;each element of <var>B</var> belongs to <var>V</var>;<br>			2)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if <var>x</var> belongs to <var>V</var>, so do its consequences<br>			3)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<var>V</var> contains only elements that belong to it on account of 1 and 2.</p><p>The pattern of my program was as follows:<br>			<br>			<var>C</var> := <var>B</var>; <var>V</var>:= empty;<br><u>do</u> <var>C</var> &#x2260; empty &#x2192; choose an arbitrary element <var>c</var> from <var>C</var> ;<br>			&nbsp;&nbsp;&nbsp;&nbsp;transfer <var>c</var> from <var>C</var> to <var>V</var> ;<br>			&nbsp;&nbsp;&nbsp;&nbsp;extend <var>C</var> with all consequences of <var>c</var> that do not<br>			&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;belong to the (disjoint) union <var>C</var> + <var>V</var><br>			<u>od</u></p><p>It is worth noticing that the intersection of <var>C</var> and <var>V</var> remains empty and that under the assumption that the time needed for the test for set-membership does <u>not</u> depend on the size of the set concerned, the timetaken by this algorithm is <u>absolutely</u> independent of the choice for <var>c</var>: at each repetition the set <var>V</var> is extended with one new element.</p><p>In the case that the graph is a rooted tree, whose root node is taken as <var>B</var>, the problem of finding the transitive closure is also known under another name: traversing a tree. Its standard solution is a recursive one, stronger: the recursive solution for tree-traversal is often regarded as the prototype application for recursive procedures. If we compare the recursive tree-traversal with the above, more general, algorithm for the transitive closure, we see that the role of <var>C</var> is taken over by the anonymous stack. This can be done because in the case of tree-traversal the test, whether consequences of <var>c</var> are members of <var>C</var>+<var>V</var> can be suppressed: the absence of cycles in a tree guarantees that we shall never &quot;meet&quot; the same node more than once.</p><p>In my innocence, I had always regarded this recursive solution fortree-traversal etc. as a, in some sense, basic and fundamental algorithm,and for years I have taken the central role of anonymous stacks for granted.It was a little bit of a shock for me to discover that the anonymity of thestack is only allowed, provided that we restrict ourselves to a rather specialcase of a more general (and perhaps in its general form more &quot;fundamental&quot;)problem, viz. the transitive closure. It made me wonder, whether in the lastfifteen years &#x2014;since LISP and ALGOL 60, say&#x2014; we have perhaps over-emphasized recursive solutions, and have taken the last-in-first-out strategy for choosing <var>c</var> &#x2014;often purely a matter of convenience, as far as storage management is concerned!&#x2014; so much for granted, that the rediscovery of the freedom toselect an <u>arbitrary</u> element <var>c</var> from <var>C</var> could rank as a scientific discovery of some sort.</p><p>The above may shed some light on current linguistic exercises in artificialintelligence work. A last-in-first-out queueing discipline engenders&#x2014;as every operating system designer knows&#x2014; the danger of individual starvation, and if the purpose of the algorithm is to traverse a finite portion of a potentially infinite tree, the last-in-first-out strategy is clearly unacceptable (whether other strategies will lead to acceptable performance is a question that falls outside the scope of this note). When, however, these linguistic exercises give birth to some system of recursive co-routines, should we not then raise the question, whether such exercises are not drastic enough, are only half-hearted attempts at freeing ourselves from the shackles of recursive solutions, which, perhaps, have dominated the scene already too long? (If the mere suggestion that recursive solutions may fail to be a cure for all our problems, don't blame me!)</p><p>The question, among other things, hinges upon the assumption that the problem of the transitive closure for directed graphs in which arrows may merge, is &#x2014;besides being a logical generalization of the tree-traversal&#x2014;a sufficiently frequently recurring theme to give it the status of &quot;centralproblem&quot;. I cannot collect all evidence in the world, but I can give yousome. Last Saturday morning the postman delivered two reports at my doorstep:&quot;A case for the <u>for</u>-statement&quot; by Edouard Marmier (ETH Zurich) and &quot;Constructingcorrect and efficient concurrent programs&quot; by M. Sintzoff and A. van Lamsweerde (MBLE Brussels)and I had a pleasant weekend studying them. When Marmier has remarked thatfor the sake of robustness, implementations should enforce a certain requirement&#x2014;one of non-interference, essentially&#x2014; he ends that paragraph by observingthat even without additional information in the program text &quot; . . . the problemof enforcing the requirement is only of moderate difficulty, since it reducesto the problem of forming the transitive closure of a directed graph. Forthis, a nicely implementable algorithm exists.&quot; The major part of the reportby Sintzoff and van Lamsweerde is concerned with the problem of reducing thenumber of dynamic re-evaluations of synchronizing conditions. But the wholeproblem of determining, which sleeping processes can be woken up is one ofdetermining a transitive closure! (A process goes to sleep when execution ofa critical activity would cause violation of the imposed invariant relation.Such a critical activity remains pending until, after completion of anothercritical activity, it is detected that it could and decided that it shouldbe fired. Such a secondary critical activity may enable other pending onesto proceed and the waking-up should continue until the fired critical activitieshave caused a state in which none of the still pending critical activitiesis kept pending without justification: only then the waking-up obligationshave been fulfilled. The waking up has exactly the same cascading nature&#x2014;with &quot;merging arrows&quot; included&#x2014; as the detection of the transitive closureof a directed graph.) Was it entirely accident, that these two reports weredropped on my doormat simultaneously?</p><center>*&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*<br>			*</center>While pondering about all this, it struck me that there is anotherarea in which we encounter rooted trees, viz. the states of terminatingcomputations in a (finite state) <u>deterministic</u> automaton: if we so desire,we can distinguish a forest of trees, with a one-to-one correspondence betweenterminal states and (roots of) trees. The question of the weakest precondition for terminating in a given final state amounts to traversing the<u>tree</u> with that final state as its root node. But consider now the non-deterministic automaton, in which some states may have a set of possible successorstates. From a very operational point of view, one may feel forced to introducesome &quot;ghost-input&quot;, because, without it, the automaton would not &quot;know&quot;which way to go: logically, however, this amounts to squeezing the non-deterministicautomaton into the straitjacket of the deterministic one.		<p>(In the process of mathematical discovery, the introduction of &quot;something&quot;, from which then later can be &quot;abstracted&quot; is an utterly respectable one. But, once such an abstraction has been discovered, from a methodological point of view, I always feel that then the concept should be given its independent right of existence if it is to bear fruit. First Descartes introduces coordinates by choosing the axes arbitrarily; it is when the arbitrariness of this choice is fully realized, that coordinate-free methods are born, and I hope never to forget my excitement when I saw the following proof (from the lectures of J.Haantjes) of the fact that the perpendiculars of a triangle go through one and the same point. It defines <var>H</var> as the intesection of two perpendiculars and shows that the line through <var>H</var> and the third angle is also a perpendicular:<br>			&nbsp;&nbsp;&nbsp;&nbsp;given: &nbsp;&nbsp;(<var>a</var> &nbsp;&#x2212;&nbsp; <var>h</var>) &nbsp;*&nbsp; (<var>b</var> &nbsp;&#x2212;&nbsp; <var>c</var>) &nbsp;=&nbsp; 0<br>			&nbsp;&nbsp;&nbsp;&nbsp;given: &nbsp;&nbsp;(<var>b</var> &nbsp;&#x2212;&nbsp; <var>h</var>) &nbsp;*&nbsp; (<var>c</var> &nbsp;&#x2212;&nbsp; <var>a</var>) &nbsp;=&nbsp; 0<br>&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;------------------------------- +<br>&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&#x2212;(<var>c</var> &nbsp;&#x2212;&nbsp; <var>h</var>) &nbsp;*&nbsp; (<var>a</var> &nbsp;&#x2212;&nbsp; <var>b</var>) &nbsp;=&nbsp; 0 &nbsp;&nbsp;&nbsp;Q.E.D.<br>The usual high-school proof is by tortuously constructing another triangle, ofwhich the original perpendiculars are the bisectors. So much for the fruits!)</p>		<p>The removal of the restriction to deterministic automata means thatour &quot;backward scan&quot; can no longer be viewed as traversing a rooted tree, because such backward paths are now allowed to merge. (In this discussion itseems irrelevant that, if we want the weakest precondition it is not exactlythe predecessor relation that we want the transitive closure of; we havesomething like<br>			1)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;all states satisfying <var>R</var> are in <var>V</var><br>			2)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;each state whose successor set is in <var>V</var>, is itself in <var>V</var> as well.<br>			The important thing is that we have departed from rooted trees.)</p>		The methodological question that I am tempted to raise is the following:could the problem presented by generalizing the current theory of denotationalsemantics so as to cover non-determinism as well, be related to a preponderantrole of recursive definitions, in a way &quot;pushing&quot; trees where more generalgraphs are needed?		<center>*&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*<br>			*</center>		<p>The next question to which I may need the answer by the time that I can formulate it precisely, is the following. Assuming that the formation of some sorts of transitive closures do indeed play the fundamental role that I currently do not exclude &#x2014;all evidence in either direction would be most welcome!&#x2014; and assuming that a &quot;machine code&quot; can be designed in which suchoperations are regarded as primitive, while we hope that they can be implementedby highly associative techniques, involving concurrent activity &quot;allover the place&quot;; assuming further, that such a machine code suggests solvability of a problem in orders of magnitude less exploding number of stepsthan today's complexity theory tells us. It certainly implies that my &quot;machine&quot;will be hard to build; will it also imply the impossibility to do so? I justdon't know, to what extent the results of complexity theory can be carriedover to unusual techniques. For instance, finding the shortest connectionbetween two nodes of an undirected graph with positive edge-lengths is polynomialor something in the number of nodes and/or edges. How much of thatargument, however, is applicable to the analogue device, that is made byreplacing the edges by gas tubes of proportional lengths and applying avoltage difference between the two nodes? The spark will choose the shortestpath. In polynomial time...?</p><p>If the above is clarifying or inspiring for any of its readers, I amglad that he saw it. If it evokes possibly helpful comments, I shall be gladto receive them.</p><table width="100%">			<tr>				<td>14th October 1974<br>					Burroughs<br>					Plataanstraat 5<br>					NEUNEN &ndash; 4565<br>					The Netherlands</td>				<td valign="top" width="40%">prof.dr.Edsger W.Dijkstra<br>					Research Fellow</td>			</tr>		</table><br />		<hr />		<font size="-1"><br />			Transcription by Moti Ben-Ari.<br>			Revised <csobj format="MedDate" h="13" region="15" t="DateTime" w="87">Fri, 13 Oct 2006</csobj>.</font></body></html>