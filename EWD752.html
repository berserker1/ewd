<!DOCTYPE html>
<html>
<head>
  <title>Distributed Arbitration</title>
  <link href="https://fonts.googleapis.com/css?family=Lobster|Raleway" rel="stylesheet">
  <link href="assets/common.css" rel="stylesheet">
  <link href="assets/transcriptions.css" rel="stylesheet">
  <meta name="generator" content="convertArticle.pl">
</head>
<body>
<div class="metabar">
  <div class="metabar-inner">
    <a href="index.html">HOME</a>
  </div>
</div>
<h1>Distributed Arbitration</h1>
<div class='body'>         
             
             <p class="noindent">DRAFT
<p class="noindent"><b>Distributed Arbitration.</b> 
<table width=100%><tr><td valign=top width=10%>
</td><td>by Edsger W. Dijkstra and C.S. Scholten
</td>  </tr>  </table>
<p class="noindent"><b>0. Problem Description.</b>
<p>Generalizing the synchronisation paradigm of the Dining Philosophers [1, 2], we consider a finite undirected graph,  
whose vertices are called “philosophers” and whose edges are called “forks”.  
A philosopher is a process consisting of a continued alternation of two states called “thinking” and “eating” respectively. 
A fork is a resource shared between the two philosophers it joins;  it is either free or owned by one of those two philosophers.
The statement “a philosopher is eating” is equivalent to the statement that the philosopher owns all the forks it shares with others. 
Note that for a complete graph the above corresponds to total mutual exclusion, with evidently “eating” corresponding to the critical section; the case of the graph being a pentagon corresponds to the paradigm mentioned above. 
<p>Even in the case of complete 2-graph there is a problem, viz. the resolution of the contention for the single fork when the two philosophers happen to become simultaneously ready to stop thinking. 
  We postulate this problem of binary arbitration solved.  
  The contention invites us to introduce after thinking and before eating an intermediate state called “ready to grab” the fork. 
  We can now formulate more precisely our postulate: 
<table width=100%><tr><td valign=top width=10%>
P0</td><td>a fork is owned <b>or</b> no philosopher is ready to grab it. </td>  </tr>  </table>
With thinking periods of <em>positive</em> duration and eating periods of <em>finite</em> duration &mdash;and we shall assume this to be the case for the rest of our paper&mdash; we immediately derive from P0 following corollary 
<table width=100%><tr><td valign=top width=10%>
C0</td>
<td>a  philosopher ready to grab a fork owned by an eating philosopher will own that fork upon completion of the other’s meal. (It is understood that a thinking philosopher owns no forks.)
</td>  </tr>  </table>
It follows that the postulated solution for the complete 2-graph is free from the the dangers of deadlock and of individual starvation. 
<p>We propose to solve the synchronization problem corresponding to a general graph in terms of binary arbitration as described above. 
In order to give the adjective “distributed” the strongest possible meaning, we accept the constraint that in any state a philosopher may 
be ready to grab <em>at most one specified</em> fork; 
as before, the state “ready to grab a specified fork” is terminated only by grabbing it. 
Consequently, a philosopher is from now on a process consisting of a repetition of 
<table width=100%><tr><td valign=top width=10%>
</td>
<td>thinking ;
</td></tr><tr><td valign=top>
</td>
<td>grabbing its forks in some order ;
</td></tr><tr><td valign=top>
</td><td>eating
</td>  </tr>  </table>
<p>For the sake of realism we admit after the atomic act of grabbing a fork a finite delay before the new owner enters its next state, in particular before it becomes ready to grab the next fork. 
For our later analysis it is then irrelevant whether, at the end of an eating period, the forks are released simultaneously or not. 
<p class="noindent"><b>1. Avoiding the danger of deadlock. </b>
<p>As long as a philosopher is ready to grab a fork (which &mdash;see P0&mdash; is owned by another) it is said to be “blocked” by that fork; the fork in question is called the “blocking fork” of that philosopher. 
<p>Deadlock &mdash;sometimes called &ldquo;partial deadlock&rdquo;&mdash; occurs when there exists a philosopher such that there is no possible future state in which it is eating. 
Without constraints on the orders in which philosophers grab their forks, the danger of deadlock is present when the graph contains a cycle: let each philosopher on that cycle grab its “left fork” first. 
In the sequel we shall formulate the precise constraint on the grabbing orders that exorcizes the danger of deadlock. 
<p>For each philosopher in a connected subset of (two or more) philosophers we define &ldquo;its first fork in that subset” to be the first fork in its grabbing order that it shares with any other philosopher in that subset. 
In each connected subset “directed paths of first forks” are recursively defined by
<table width=100%><tr><td valign=top width=10%>1)
</td><td> a single philosopher is a directed path  of first forks </td></tr><tr><td valign=top>2)
</td>
<td> a directed path of first forks extended with the first fork of its last 
philosopher is a directed path of first forks. </td>  </tr>  </table>
<p>Since each philosopher in a connected subset has a first fork in that (finite) subset, 
cyclic directed paths of first forks exist. 
<p class="noindent"><b>Theorem 0.</b> “the danger of deadlock is present” = “there exists a connected subset containing a cyclic directed path of more than two first forks”. End of Theorem 0. 
<p class="noindent"><b>Remark.</b> Note that in the terminology used, a 
”cyclic directed path of two first forks” corresponds to a single fork that is first fork at both ends. (End of Remark.) 
<p class="noindent"><b>Proof of Theorem 0. </b>
<p>Assume the existence of a subset containing a cyclic directed path of three or more first forks. 
The state in which each philosopher on the cyclic path owns its first fork can be reached when all the philosophers outside the subset are thinking. 
Since none of the philosophers on the cycle can be the first to eat, deadlock occurs. 
Hence the truth of the right-hand side implies the truth of the left-hand side. 
<p>Assume deadlock. This implies eventually the existence of a directed cycle of more than two blocking forks, hence of a directed cycle of forks each owned by, say, its target. 
If there exists an owned “diagonal” fork of the cycle, there exists a smaller directed cycle of at least three owned forks (built from the “diagonal” and one part of the original cycle). 
By induction we conclude the existence of a directed cycle of at least three owned forks, no diagonal of which is owned. 
In the subset formed by the philosophers on such a cycle, the forks of the cycle are the first forks of their owners. 
Hence the truth of the left-hand side implies the truth of the right-hand side. (End of proof of Theorem 0.) 
<p>We state the following corollary of Theorem 0 
<table width=100%><tr><td valign=top width=10%>
C1:</td>
<td>In a deadlock-free system with at least one fork, there exists at least one fork that is first fork at both ends.
</td>  </tr>  </table>
<p class="noindent"><b>Remark.</b> Since each fork blocks at most one philosopher at a time, absence of the danger of deadlock implies, thanks to P0, the absence of the danger of individual starvation. (End of remark.) 
<p>In the sequel we confine our attention to systems free from the danger of deadlock. 
<p class="noindent"><b>2. Blocking paths and delays.</b>
<p>So-called blocking paths are defined recursively by 
<table width=100%><tr><td valign=top width=10%>
1)</td><td>a single philosopher is a blocking path
</td></tr><tr><td valign=top>
2)</td>
<td>a blocking path extended with the blocking fork of its last philosopher is a blocking path.
</td>  </tr>  </table>
<p>Let <var>X</var> be a philosopher. For the blocking paths that starts at <var>X</var> we define the following meaningful order. Consider two such paths: 
<table width=100%><tr><td valign=top width=10%>
1)</td><td>if one path is an extension of the other, the extended path precedes the other
</td></tr><tr><td valign=top>
2)</td><td>If neither is an extension of the other, they contain a philosopher <var>Y</var> such that both paths are identical 
from <var>X</var> to <var>Y</var> but are extended by different blocking forks of <var>Y</var>; the order in which <var>Y</var> grabs these two forks equals the order of the corresponding paths. </td>  </tr>  </table>
<p>The above ordering of the blocking paths that start at <var>X</var> is meaningful for the following reason. 
Associate with each blocking path the following state: philosophers not on the path are thinking and the last philosopher on the path is eating. 
Upon completion of the current meal, a possible successor state of the system 
is the one associated with the next blocking path, where “next” 
is to be understood in terms of the above ordering 
of the blocking paths starting at <var>X</var>. (See the last paragraph of Section 0.) 
<p>Whenever <var>X</var> is not thinking, there is a 
unique blocking path starting at <var>X</var> and with 
its last philosopher eating. it now follows that 
the maximum number of meals that can take 
place between two successive thinking periods 
of <var>X</var> &mdash;called “the maximum delay for <var>X</var>”&mdash; 
equals the number of blocking paths starting at <var>X</var>. 
<p class="noindent">From the previous paragraph it follows that a delay 
equal to the number of blocking paths starting at  
  <var>X</var> can occur; from corollary C0 it follows that 
the delay for <var>X</var> cannot exceed that number. 
<p class="noindent"><b>3. Minimum average maximum delay for mutual exclusion.</b>
<p>For the sake of simplicity we shall confine
ourselfs in the following two sections to complete 
graphs, i.e. a fork for each pair of philosophers. 
This corresponds to total mutual exclusion of the eating periods. 
From section 2 we conclude that the problem of minimizing maximum delays boils
 down to minimizing numbers of blocking paths; minimizing, for a given set 
of philosophers, their average maximum delay is, therefore, tantamount 
to minimizing the total number of blocking paths. 
<p>For <var>N</var> philosophers we shall now determine the minimum number of blocking paths. 
Let in a deadlock-free system fork <var>f</var>, shared by philosophers <var>x</var> and <var>y</var>, be first fork at both ends; the existence of <var>f</var> is stated in corollary C1. 
The blocking paths of the system can now be partitioned as follows: 
<table width=100%><tr>
<td valign=top width=10%> <var>A</var></td><td>Blocking paths containing neither <var>X</var> nor <var>Y</var></td></tr><tr><td valign=top>
  <var>BX</var></td><td>Blocking paths containing  <var>X</var> but not <var>Y</var> and blocking paths starting at <var>Y</var> with <var>X</var> in second position </td></tr><tr><td valign=top>
    <var>BY</var></td><td>Blocking paths containing  <var>Y</var> but not <var>X</var> and blocking paths starting at <var>X</var> with <var>Y</var> in second position </td>  </tr>  </table>
<p class="noindent"><b>Note.</b> Because <var>f</var> is the first fork of both <var>X</var> and <var>Y</var>, a blocking path containing both starts at one of them with the other in second position. (End of note.) 
<p>Let us call <var>SX</var> the reduced system that remains when philosopher <var>Y</var> is removed (forks shared by <var>y</var> being removed from the grabbing orders of the others); 
For this reduced system, <var>X</var> will be denoted as “the pivotal philosopher”. 
The system <var>SY</var> is similarly defined by interchanging <var>X</var> and <var>Y</var>. 
<p>A blocking path from category <var>A</var> occurs in both reduced systems, independently of the place a pivotal philosopher occupies in the 
grabbing orders of the non-pivotal ones and vice versa. 
<p>The blocking paths from category <var>BX</var> are fully determined by the structure of <var>SX</var>, and similarly for <var>BY</var>. 
<p>Let <var>PX</var> and <var>PY</var> be the number of blocking paths in <var>BX</var> and <var>BY</var> respectively. 
In a system with a minimal number of blocking paths, <var>PX</var> = <var>PY</var> holds, because if <var>PX</var> < <var>PY</var>, 
we can decrease <var>PY</var> without affecting either <var>PX</var> or the number of <var>A</var>-paths by choosing the
structure of <var>SY</var> equal to that of <var>SX</var>. 
(Since deadlock implies infinitely many blocking paths, this transformation does not 
introduce the danger of deadlock.) 
<p>In short, heading for systems with a minimal number of blocking paths, we can confine ourselves 
to systems with <var>SX</var> and <var>SY</var> of equal structures 
(i.e.  replacing <var>X</var> in <var>SX</var> by <var>Y</var> yields <var>SY</var>.)
<p>The equal structure of <var>SX</var> and <var>SY</var> implies that <var>X</var> and <var>Y</var> have equal grabbing orders and that each non-pivotal philosopher has the forks it shares with <var>x</var> and <var>y</var> in adjacent positions in its grabbing order. 
Thus we have to focus our attention on the reduced structure of <var>N</var>&ndash;1 philosophers. 
Repeated application ends with a structure of two philosophers. 
<p>The inverse process starts with two philosophers connected by one fork, and builds up the system by increasing the number of philosophers by one in each step. 
Such a step consists of &ldquo;doubling&rdquo; a selected philosopher. 
The fork connecting the pair is first fork for both, the rest of their grabbing orders is a copy of that of the selected philosopher; the grabbing orders of the other philosophers are &ldquo;stretched&rdquo; at the position of the selected philosopher, whose entry is replaced by the resulting pair in some order. 
<p>The structure satisfies relation. 
<table width=100%><tr><td valign=top width=10%>
R:</td><td>The number of philosophers in the structure equals 1 <b>or</b> the philosophers can 
be partitioned into two non-empty subsets <var>V</var> and <var>W</var> such that
<table width=90%><tr><td valign=top width=10%>
1)</td><td>each philosopher grabs the forks it shares with members of its own set before it grabs those it shares with members of the other set , and
</td></tr><tr><td valign=top>
2)</td><td>the structures corresponding to <var>V</var> and <var>W</var> both satisfy R. </td>  </tr>  </table>
 
</td>  </tr>  </table>
<p>This is vacuously true to start with and remains 
true under the doubling operation: when a selected 
philosopher is doubled, the resulting pair belongs 
to the same set(s) as the philosopher it replaces. 
<p>A blocking path starting at a philosopher from <var>V</var> either has all its philosophers in <var>V</var> or is any 
of those paths extended with one arbitrary philosopher 
from <var>W</var>. (Firstly, such an extension is a blocking path; 
secondly, it cannot be extended 
with a further philosopher from <var>W</var>, since the last 
philosopher of the path has already grabbed all 
forks it shares with other members of W; 
thirdly, it cannot be extended with a philosopher from <var>V</var> either, since the  
last <var>V</var>-philosopher on 
the path owns all the forks it shares with the other
members of <var>V</var>.) It follows that the 
total number of blocking paths equals: 
<table width=100%><tr><td valign=top width=10%>
</td>
<td>(<var>NW</var> + 1) &middot; <var>PV</var> + (<var>NV</var> + 1) &middot; <var>PW</var> , </td></tr><tr><td valign=top>
where</td><td><var>NV</var> = number of philosophers in <var>V</var></td></tr><tr><td valign=top>
</td><td><var>NW</var> = number of philosophers in <var>W</var></td></tr><tr><td valign=top>
</td><td><var>PV</var> = number of blocking paths in <var>V</var></td></tr><tr><td valign=top>
</td><td><var>PW</var> = number of blocking paths in <var>W</var></td>  </tr>  </table>
<p>Let f(<var>x</var>) be the minimum number of
blocking paths in a system with <var>x</var> philosophers. 
Since our freedom in selecting the philosopher 
to be doubled enables us to realize any 
partitioning (and subsequent subpartitionings), our 
previous result tells us that f is the minimal 
solution of 
<table width=100%><tr><td valign=top width=12%>
for <var>x</var>=1:</td>
<td width="88%">f(<var>x</var>) = 1 </td></tr><tr><td valign=top>
for <var>x</var>&gt;1:</td>
<td>f(<var>x</var>) = (<var>n</var>+1) &middot; f(<var>m</var>) + (<var>m</var>+1) &middot; f(<var>n</var>) </td></tr><tr><td valign=top>
</td><td>where <var>m</var>&ge;1, <var>n</var>&ge;1, <var>m</var>+<var>n</var>=<var>x</var></td>  </tr>  </table>
<p>It can be shown that the minimal solution is 
obtained by choosing |<var>m</var>&ndash;<var>n</var>| &le; 1. (See Appendix.) 
<p class="noindent"><b>4. Configurations symmetric in the philosophers.</b>
<p>From the previous section it follows that the 
minimal number of blocking paths can always be 
realized by assigning to each fork a natural number, 
called its “rank”, such that 
<table width=100%><tr><td valign=top width=10%>
1)</td><td>forks meeting at a philosopher have distinct ranks, and
</td></tr><tr><td valign=top>
2)</td><td>each philosopher grabs its forks in the order of increasing rank.
</td>  </tr>  </table>
We call such systems “ranked systems”. (Ranked 
systems are obviously deadlock-free.) 
<p class="noindent"><b>Example.</b> By way of illustration we give a system 
that is deadlock-free, is symmetric in the philosophers, 
and realizes the minimum number of blocking paths, 
but cannot be ranked. With four philosophers numbered 
0, 1, 2, 3 and addition being modulo 4, philosopher 
  <var>i</var> grabs the forks it shares with <var>i</var>+2, 
  <var>i</var>+1, and <var>i</var>+3 in that order. We don’t need to consider 
that system; there is, indeed, a ranked 
system enjoying the same properties: it suffices  
to re-interpret “addition” as the bit-wise sum modulo  
2. (End of example.) 
<p>In general, for a ranked system of <var>N</var> philosophers, 
the number of distinct ranks exceeds the 
number of forks meeting at a philosopher, e.g. 
  <var>N</var>=3 requires 3 distinct ranks. In such a case, 
symmetry in the philosophers is precluded: in a  
symmetric ranked system each philosopher grabs 
a fork of each rank in the system. 
<p>In a symmetric ranked system, forks of two 
distinct ranks form cycles of length 4; their 
diagonals have a third rank. 
<p class="noindent"><b>Proof.</b> Let <var>p</var> and <var>q</var> be two distinct ranks. 
Consider the two 2-fork paths (<var>p</var>,<var>q</var>) and (<var>q</var>,<var>p</var>), 
starting at the same philosopher. The latter shares 
with their endpoints forks which, for reasons of symmetry, 
have the same rank, <var>r</var> say. Hence their 
endpoints coincide. Obviously, the other diagonal 
is of rank <var>r</var> as well. (End of proof.) 
<p>Consider a symmetric ranked system of more
than 2 philosophers. Two ranks partition therefore
the philosophers into partitions of 4. Forks 
of a next rank either connect philosophers from 
the same partition, or pair partitions, thereby 
doubling their size and halving their number. 
The number of philosophers in a symmetric 
ranked system is, therefore, a power of 2. 
<p>Furthermore a symmetric ranked system 
exists for each <var>N</var>=2<sup><var>k</var></sup>. Number the philosophers 
(in binary) from 0 through <var>N</var>&ndash;1, and assign to 
the fork shared by philosophers <var>i</var> and <var>j</var> the 
rank <var>i</var>+<var>j</var>, where “addition” is again the bit-wise 
sum modulo 2. If <var>X</var> is the number of a philosopher, 
we can renumber the philosophers without affecting the ranks by 
performing for each philosopher number <var>i</var>: <var>i</var>:=<var>i</var>+<var>X</var> (addition again bit-wise 
modulo 2). In the new system &mdash;which
is congruent with the old one&mdash; philosopher 
<var>X</var> has become philosopher 0, and thus the symmetry 
has been established. 
<p>It follows from our previous section that for <var>N</var>=2<sup><var>k</var></sup> 
the above symmetric ranked system realizes the 
minimum number of blocking paths, hence the minimum 
maximum delay for each philosopher. It follows from
that same section that this delay equals unfortunately 
<table width=100%><tr><td valign=top width=10%>
</td><td>(PROD <var>i</var>: 0 &le; <var>i</var> &lt; <var>k</var>: 1 + 2<var><sup>i</sup></var>) ,
</td>  </tr>  </table>
<table width="299"> 
<tr><td width="48">i.e.</td><td width="33"><var>k</var>:</td><td width="69">delay:</td><td width="129"><var>N</var>:</td></tr>    
<tr><td>&nbsp;</td><td>0</td><td>1</td><td>1</td></tr>    
<tr><td>&nbsp;</td><td>1</td><td>2</td><td>2</td></tr>    
<tr><td>&nbsp;</td><td>2</td><td>6</td><td>4</td></tr>    
<tr><td>&nbsp;</td><td>3</td><td>30</td><td>8</td></tr>    
<tr><td>&nbsp;</td><td>4</td><td>270</td>
  <td>16 &nbsp;&nbsp;&nbsp;&nbsp;and so on.</td></tr>    
</table> 
<p>The exploding worst case casts some doubts on the general utility of binary arbitration as a means for implementing mutual exclusion. 
We can only recommend it when it can be shown on other grounds &mdash;such as timing considerations&mdash; that the worst case delay will not occur. 
<p class="noindent"><b>5. A two-stage solution.</b> 
<p>The case of the complete graph, corresponding to total mutual exclusion, was studied in order to determine how bad worst-case delays could be. 
We now return to the general graph, for which we shall propose a different solution. 
At the level of detail in which it will be described, it uses less austere communication facilities than binary arbitration only, but it achieves the smallest possible worst-case delay. 
<p>For this purpose, the life of a philosopher is viewed as a cyclic succession of three states, called “thinking”, “hungry”, and “eating” respectively; for brevity’s sake the union of the last two states will be denoted by “tabled”. 
<p>Furthermore, also each fork has three states: either it is undirected or it is directed, i.e.  it carries an arrow in one of the two possible directions. 
<p>The life of a philosopher is now programmed as follows, angle brackets being used to 
delimit “point actions”, philosophers sharing a fork are called each other’s neighbours. 
<p class="noindent">
<table width=100% cellpadding="0" cellspacing="0"><tr><td valign=top width=10%>
<b>do</b></td><td>true &rarr;
</td></tr><tr><td valign=top>
</td><td>thinking;
</td></tr><tr><td valign=top>
T0:</td><td>&lt;directs an arrow towards each of its tabled neighbours
and switches to hungry, hence to tabled&gt; 
</td></tr><tr><td valign=top>
</td><td>hungry;
</td></tr><tr><td valign=top>
T1:</td><td>&lt;observes to be without outgoing arrows and switches to eating,
hence remains tabled&gt; 
</td></tr><tr><td valign=top>
</td><td>eating
</td></tr><tr><td valign=top>
T2:</td><td>&lt;makes all its forks undirected and switches to thinking&gt;
</td></tr><tr><td valign=top>
<b>od</b></td><td>
</td>  </tr>  </table>
<p>The system, which is started with all philosophers thinking and all forks undirected, maintains the following invariants: 
<table width=100%><tr><td valign=top width=10%>
Q0:</td><td>for each pair of neighbours <var>X</var> and <var>Y</var> “both <var>X</var> and <var>Y</var> are tabled” = “the fork shared by <var>X</var> and <var>Y</var> is directed”
</td></tr><tr><td valign=top>
Q1:</td><td>for each philosopher <var>X</var> “<var>X</var> is hungry” <b>or</b> “<var>X</var> is without outgoing arrows”.
</td>  </tr>  </table>
<p>As a consequence of Q0, a thinking philosopher has all its forks undirected; as a consequence of Q1, T2 removes only incoming arrows. 
The universal truth of Q0 and Q1 precludes simultaneously eating neighbours. 
<p>In order to prove that transitions T1 &mdash;which are implemented by making a philosopher “wait” until all its outgoing arrows have disappeared&mdash; cannot lead to deadlock, we observe the obvious invariance of 
<table width=100%><tr><td valign=top width=10%>
Q2:</td><td>directed forks do not form directed cycles.
</td>  </tr>  </table>
<p>The system is free from the danger of individual starvation. Observe a hungry philosopher <var>X</var> and all philosophers reachable from <var>X</var> via directed forks. 
All philosophers of this directed subgraph are tabled, hence that subgraph cannot grow. 
It is furthermore cycle-free (on account of Q2): its longest path ends at a philosopher that can eat and, hence, that maximum path length gives an upper bound for the delay of <var>X</var>. 
With <var>N</var> philosophers, the delay is therefore at most <var>N</var>. 
<p>Nice as this solution is, it begs the question, since the only safe way of implementing the T’s &mdash;in particular T0 and T2&mdash; as sequential processes that we know of is to make the T’s of neighbours mutually exclusive in time, and that mutual exclusion was the original problem. 
<p>Under the assumption that both thinking and eating of a philosopher always require more than <var>N</var> &ldquo;transition times T&rdquo;, an 
implementation of the mutual exclusion of neighbouring T’s by means of binary arbitration yields, on the microscopic level, a delay of at most <var>&ldquo;</var> transition times. 
<p>The moral of the story is that an algorithm with very poor worst-case behaviour can be safely used when embedded in an environment that prevents the realization of the poor performance. 
<p class="noindent"><b>References  </b>
<table width=100%><tr><td valign=top width=10%>
[1]</td>
<td>Hoare, C.A.R., &ldquo;Towards a Theory of Parallel Programming&rdquo;. <i>Operating Systems Techniques</i>, Ed. C.A.R. Hoare and R.H. Perrott, Academic Press, London and New York, 1972, pp 61–71. </td></tr><tr><td valign=top>
[2]</td>
<td>Dijkstra, Edsger W., &ldquo;Hierarchical Ordering of Sequential Processes&rdquo;, ibid.
pp 72–93. 
</td>  </tr>  </table>
<p class="noindent"><b>Appendix </b>
<p class="noindent">The claim that the system 
<table width=100% cellpadding="0" cellspacing="0"><tr><td valign=top width=18%>
for <var>x</var>=1:</td><td width="82%">f(<var>x</var>) = 1 </td></tr><tr><td valign=top>
for <var>x</var>>1:</td>
<td>f(<var>x</var>) = (<var>n</var>+1)∙f(<var>m</var>) + (<var>m</var>+1)∙f(<var>n</var>) </td></tr><tr><td valign=top>
</td>
<td>where <var>m</var>&ge;1, <var>n</var>&ge;1, <var>m</var>+<var>n </var>= <var>x</var></td>  </tr>  </table>
yields its minimal solution for |<var>m</var>–<var>n</var>| &le; 1 is equivalent to
the statement that the function f defined by 
<table width=100% cellpadding="0" cellspacing="0"><tr><td valign=top width=10%>
</td><td>f(1) = 1                               </td>
<td> ⎫
</td></tr><tr><td valign=top>
</td>
<td>f(2∙<var>k</var>) = (<var>k</var>+1)∙f(<var>k</var>) + (<var>k</var>+1)∙f(<var>k</var>) </td>
<td>⎬ for <var>k</var> &ge; 1 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;
</td></tr><tr><td valign=top>
</td>
<td>f(2∙<var>k</var>+1) = (<var>k</var>+1)∙f(<var>k</var>+1) + (<var>k</var>+2)∙f(<var>k</var>) </td>
<td> ⎭
</td>  </tr>  </table>
satisfies for <var>m</var>&ge;1, <var>n</var>&ge;1, P(<var>m</var>,<var>n</var>) &ge; 0 with P defined by 
<table width=100%><tr><td valign=top width=10%>
</td>
<td>P(<var>m</var>,<var>n</var>) = (<var>m</var>+1)∙f(<var>n</var>) &ndash; f(<var>m</var>+<var>n</var>) + (<var>n</var>+1)∙f(<var>m</var>) </td><td align=right>(0)
</td>  </tr>  </table>
<p>With Q defined by 
<table width=100%><tr><td width=8% height="20" valign=top>
</td>
<td width="86%">Q(<var>m</var>,<var>n</var>) = <var>m</var>∙f(<var>n</var>) &ndash; <var>n</var>∙f(<var>m</var>)  </td>
<td width="6%"><div align="right">(1)</div></td>
</tr>  
  </table>
we prove first 
<table width=100%><tr><td valign=top width=10%>
</td><td><var>m</var>&le;<var>n</var> &rArr; Q(<var>m</var>,<var>n</var>)&ge;0
</td><td align=right>(2)
</td>  </tr>  </table>
<p class="noindent"><b>Proof of (2).</b>
On account of (1), (2) follows from 
<table width=100%><tr><td valign=top width=10%>
</td><td>f(<var>x</var>)/<var>x</var> is an ascending function for <var>x</var>&ge;1
</td><td align=right>(3)
</td>  </tr>  </table>
which follows from 
<table width=100%><tr><td valign=top width=10%>
</td>
<td><var>n</var>∙f(<var>n</var>+1) &ndash; (<var>n</var>+1)∙f(<var>n</var>) &gt; 0 for <var>n</var>&ge;1
</td><td align=right>(4)
</td>  </tr>  </table>
<p>We shall demonstrate (4) by 
<table width=100%><tr><td valign=top width=5%>
a)</td><td>observing its truth for <var>n</var>=1 (note that f(2)=4), </td></tr><tr><td valign=top>
b)</td><td>demonstrating that the first difference of the
left-hand side of (4) is positive. This first difference is 
</td></tr><tr><td valign=top>
</td>
<td>(<var>n</var>+1)∙f(<var>n</var>+2) &ndash; 2∙(<var>n</var>+1)∙f(<var>n</var>+1) + (<var>n</var>+1)∙f(<var>n</var>) = </td></tr><tr><td valign=top>
</td>
<td>(<var>n</var>+1)∙(f(<var>n</var>+2) &ndash; 2∙f(<var>n</var>+1) + f(<var>n</var>)) for <var>n</var>&ge;1
</td>  </tr>  </table>
We are left with the proof that f has a positive second difference. With ddf defined by 
<table width=100%><tr><td valign=top width=10%>
</td>
<td>ddf(<var>n</var>) = f(<var>n</var>+2) – 2∙f(<var>n</var>+1) + f(<var>n</var>) </td>  </tr>  </table>
we deduce from the definition of f 
<table width=100%><tr><td valign=top width=5%>
</td>
<td>ddf(2∙<var>k</var>) = 2∙(f(<var>k</var>+1) – f(<var>k</var>)) </td></tr><tr><td valign=top>
</td><td>ddf(2∙<var>k</var>+1) = (<var>k</var>+2)∙ddf(<var>k</var>) </td>  </tr>  </table>
<p class="noindent">Since f(1) = 1, f(2) = 4, f(3) = 11 we find for
  <var>k</var>=1: f(<var>k</var>+1) &ndash; f(<var>k</var>) = 3 and ddf(<var>k</var>) = 4. From 
that base it follows by induction that all first 
and second differences of f are positive. 
Hence, (2) has been established. (End of Proof of (2)). 
<p>Next we define &mdash; with (2∙<var>k</var>) <b>div</b> 2 = (2∙<var>k</var>+1) <b>div</b> 2 = <var>k</var>&mdash; 
<table width=100% cellpadding="0" cellspacing="0"><tr><td valign=top width=33%>
<var>x</var><sub>0</sub> = <var>m</var> <b>div</b> 2</td><td><var>x</var><sub>2</sub> = <var>n</var> <b>div</b> 2
</td></tr><tr><td valign=top>
<var>x</var><sub>1</sub> = (<var>m</var>+1) <b>div</b> 2</td><td><var>x</var><sub>3</sub> = (<var>n</var>+1) <b>div</b> 2
</td>  </tr>  </table>
<p>These functions satisfy &mdash;as is easily verified&mdash;
</p>
<table width=100% cellpadding="0" cellspacing="0"><tr><td valign=top width=30%>
<var> x</var><sub>0</sub> + <var>x</var><sub>1</sub> = <var>m</var></td><td><var>x</var><sub>2</sub> + <var>x</var><sub>3</sub> = <var>n</var></td>  </tr>  </table>
{<var>x</var><sub>0</sub> + <var>x</var><sub>3</sub>, <var>x</var><sub>1</sub> + <var>x</var><sub>2</sub>} = {(<var>m</var>+<var>n</var>) <b>div</b> 2, (<var>m</var>+<var>n</var>+1) <b>div</b> 2}
<p>Using in the subscripts “∔” to denote the bit-wise
sum modulo 2, we now consider the expression 
<table width=100%><tr><td width=10% height="33" valign=top>
</td><td>(<b>S</b> <var>i</var>: 0&le; <var>i</var> &le; 2: (<var>x</var><sub><var>i</var>∔1</sub> + <var>x<sub>i</sub></var><sub>∔2</sub>+1) ∙ 
P(<var>x<sub>i</sub></var>, <var>x<sub>i</sub></var><sub>∔3</sub>) + (<var>x<sub>i</sub></var><sub>∔3</sub> - <var>x<sub>i</sub></var><sub>∔1</sub>) ∙ 
Q(<var>x<sub>i</sub></var>, <var>x<sub>i</sub></var><sub>∔2</sub>))
</td><td align=right>(5)
</td></tr>  </table>
<p>In (5) we have two types of terms </p>
<p class="noindent">a) terms derived from the middle term of P; they add up to </p>
<table width=100% cellpadding="0" cellspacing="0"><tr><td width=10% height="32" valign=top>
</td>
<td>– (<var>x</var><sub>1</sub> + <var>x</var><sub>2</sub> + 1) ∙ f(<var>x</var><sub>0</sub> + <var>x</var><sub>3</sub>) – (<var>x</var><sub>0</sub> + <var>x</var><sub>3</sub> + 1) ∙ f(<var>x</var><sub>1</sub> + <var>x</var><sub>2</sub>) =
</td></tr><tr><td height="35" valign=top>
</td>
<td>– f(<var>x</var><sub>0</sub> + <var>x</var><sub>1</sub> + <var>x</var><sub>2</sub> + <var>x</var><sub>3</sub>) =
</td></tr><tr><td height="30" valign=top>
</td>
<td>– f(<var>m</var> + <var>n</var>) . </td>  </tr>  </table>
b) terms with f(<var>x<sub>i</sub></var>) for 0 &le; <var>i</var> &lt; 4. The coefficient of f(<var>x<sub>i</sub></var>) is
<table width=100% cellpadding="0" cellspacing="0"><tr><td width=10% height="43" valign=top>
</td><td>(<var>x<sub>i</sub></var><sub><var>∔</var>1</sub> + <var>x<sub>i</sub></var><sub>∔2</sub> + 1 ) ∙ (<var>x<sub>i</sub></var><sub>∔3</sub> + 1 ) +
(<var>x<sub>i</sub></var><sub>∔1</sub> - <var>x<sub>i</sub></var><sub>∔3</sub>) ∙ (<var>x<sub>i</sub></var><sub>∔2</sub> =
</td></tr><tr><td height="40" valign=top>
</td><td>(<var>x<sub>i</sub></var><sub>∔2</sub> + <var>x<sub>i</sub></var><sub>∔3</sub> + 1 ) ∙ (<var>x<sub>i</sub></var><sub>∔1</sub> + 1) .
</td>  </tr>  </table>
Combination of the terms with <var>i</var>=0 and <var>i</var>=1 gives
<table width=100%><tr><td width=10% height="35" valign=top>
</td>
<td>(<var>x</var><sub>2</sub> + <var>x</var><sub>3</sub> + 1 ) ∙ f(<var>x</var><sub>0</sub> + <var>x</var><sub>1</sub>) = (<var>n</var>+1) ∙ f(<var>m</var>) , </td>  </tr>  </table>
Combination of the terms with <var>i</var>=2 and <var>i</var>=3 gives
<table width=100%><tr><td width=10% height="32" valign=top>
</td><td>(<var>x</var><sub>0</sub> + <var>x</var><sub>1</sub> + 1 ) ∙ f(<var>x</var><sub>2</sub> + <var>x</var><sub>3</sub>) = (<var>m</var>+1) ∙ f(<var>n</var>) . </td>  </tr>  </table>
Consequently, expression (5) equals P(<var>m</var>, <var>n</var>) .
<p>Because (<var>x<sub>i</sub></var><sub><var>∔</var>3</sub> &gt; <var>x<sub>i</sub></var><sub>∔1</sub> &rArr; <var>x</var><sub><var>i</var>∔2</sub> &ge; <var>x<sub>i</sub></var> &mdash;and
similarly (<var>x<sub>i</sub></var><sub>∔3</sub> &lt; <var>x<sub>i</sub></var><sub>∔1</sub> &rArr; <var>x</var><sub><var>i</var>∔2</sub> &le; <var>x</var><sub><var>i</var></sub>&mdash;
we conclude
om account of (2) that the second terms in (5) are &ge; 0. Therefore, P(<var>m</var>,<var>n</var>) &ge; 0 can
be concluded from
<table width=100%><tr><td valign=top width=10%>
</td><td>P(<var>m</var> <b>div</b> 2, (<var>n</var>+1) <b>div</b> 2 &ge; 0 <b>and</b> P((<var>m</var>+1) <b>div</b> 2, <var>n</var> <b>div</b> 2) &ge; 0
</td>  </tr>  </table>
<p class="noindent">This observation concludes the inductive argument.
 
<p class="noindent"><table width=100%><tr><td valign=top width=50%>
C.S. Scholten</td><td>Edsger W. Dijkstra
</td></tr><tr><td valign=top>
Philips Research Laboratories</td><td>Burroughs
</td></tr><tr><td valign=top>
5600 MD EINDHOVEN</td><td>Plataanstraat 5
</td></tr><tr><td valign=top>
The Netherlands</td><td>5671 AL NUENEN
</td></tr><tr><td valign=top>
</td><td>The Netherlands
</td>  </tr>  </table>
 
          
<hr /> 
   <p class="noindent"><font size="-1">Transcribed by Martin P.M. van der Burgt<br />   
    Last revision  
    <csobj format="MedDate" h="13" region="15" t="DateTime" w="90">
      <!-- #BeginDate format:En2 -->10-Nov-2015<!-- #EndDate -->
      <!&mdash; #EndDate &mdash;>  
    </csobj> 
  .</font></p>    
  <p>&nbsp;</p>   
</div></div></div></div>
</body></html> </div>
</body>
</html>
